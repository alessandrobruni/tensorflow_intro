{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrobruni/tensorflow_intro/blob/main/C1W3_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjHqsmTAVLU"
      },
      "source": [
        "# Week 3: Improve MNIST with Convolutions\n",
        "\n",
        "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For this exercise see if you can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model from the  assignment of the previous week. \n",
        "\n",
        "You should stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your callback.\n",
        "\n",
        "When 99.5% accuracy has been hit, you should print out the string \"Reached 99.5% accuracy so cancelling training!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZpztRwBouwYp",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrW_8rOSjoy7"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Begin by loading the data. A couple of things to notice:\n",
        "\n",
        "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
        "\n",
        "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "dAhzzxZQjoy7"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd() \n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "#data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
        "#data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path='/content/drive/MyDrive/ColabNotebooks/TFC/C1/data/mnist3.npz') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qReu-kH_G1g6",
        "outputId": "43164bb5-d60a-443d-d46e-d5ba79eabf6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images.shape"
      ],
      "metadata": {
        "id": "P6ryukppkzuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08399585-534d-4d97-e559-d18c42371d29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=320)"
      ],
      "metadata": {
        "id": "s0MptyiWmj5V"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#plt.imshow(training_images[0], cmap=plt.get_cmap('gray'))\n",
        "img0 = training_images[0]\n",
        "display(img0.shape)\n",
        "display(img0)\n",
        "plt.imshow(img0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "_JNrxgiLy5n1",
        "outputId": "fb8677ce-e29d-4ddf-9f7e-cb6211352092"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e148817d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_reshaped =training_images.reshape(training_images.shape[0],28,28,1)"
      ],
      "metadata": {
        "id": "D6mmtRY9ZPIk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO4SDFJHOmbe",
        "outputId": "46f042b3-73b3-4e57-a964-ada6523b1f9f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_reshaped_0 = training_images_reshaped[0]\n",
        "display(img_reshaped_0.shape)\n",
        "display(img_reshaped_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "77LuexEvpmbb",
        "outputId": "85a5c155-b147-4ba0-96f1-c8431ce5ecb8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  3],\n",
              "        [ 18],\n",
              "        [ 18],\n",
              "        [ 18],\n",
              "        [126],\n",
              "        [136],\n",
              "        [175],\n",
              "        [ 26],\n",
              "        [166],\n",
              "        [255],\n",
              "        [247],\n",
              "        [127],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 30],\n",
              "        [ 36],\n",
              "        [ 94],\n",
              "        [154],\n",
              "        [170],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [225],\n",
              "        [172],\n",
              "        [253],\n",
              "        [242],\n",
              "        [195],\n",
              "        [ 64],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 49],\n",
              "        [238],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [251],\n",
              "        [ 93],\n",
              "        [ 82],\n",
              "        [ 82],\n",
              "        [ 56],\n",
              "        [ 39],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 18],\n",
              "        [219],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [198],\n",
              "        [182],\n",
              "        [247],\n",
              "        [241],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 80],\n",
              "        [156],\n",
              "        [107],\n",
              "        [253],\n",
              "        [253],\n",
              "        [205],\n",
              "        [ 11],\n",
              "        [  0],\n",
              "        [ 43],\n",
              "        [154],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 14],\n",
              "        [  1],\n",
              "        [154],\n",
              "        [253],\n",
              "        [ 90],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [139],\n",
              "        [253],\n",
              "        [190],\n",
              "        [  2],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 11],\n",
              "        [190],\n",
              "        [253],\n",
              "        [ 70],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 35],\n",
              "        [241],\n",
              "        [225],\n",
              "        [160],\n",
              "        [108],\n",
              "        [  1],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 81],\n",
              "        [240],\n",
              "        [253],\n",
              "        [253],\n",
              "        [119],\n",
              "        [ 25],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 45],\n",
              "        [186],\n",
              "        [253],\n",
              "        [253],\n",
              "        [150],\n",
              "        [ 27],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 16],\n",
              "        [ 93],\n",
              "        [252],\n",
              "        [253],\n",
              "        [187],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [249],\n",
              "        [253],\n",
              "        [249],\n",
              "        [ 64],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 46],\n",
              "        [130],\n",
              "        [183],\n",
              "        [253],\n",
              "        [253],\n",
              "        [207],\n",
              "        [  2],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 39],\n",
              "        [148],\n",
              "        [229],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [250],\n",
              "        [182],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 24],\n",
              "        [114],\n",
              "        [221],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [201],\n",
              "        [ 78],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 23],\n",
              "        [ 66],\n",
              "        [213],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [198],\n",
              "        [ 81],\n",
              "        [  2],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 18],\n",
              "        [171],\n",
              "        [219],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [195],\n",
              "        [ 80],\n",
              "        [  9],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 55],\n",
              "        [172],\n",
              "        [226],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [244],\n",
              "        [133],\n",
              "        [ 11],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [136],\n",
              "        [253],\n",
              "        [253],\n",
              "        [253],\n",
              "        [212],\n",
              "        [135],\n",
              "        [132],\n",
              "        [ 16],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]]], dtype=uint8)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " plt.imshow(img_reshaped_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "RIT795YmQU5l",
        "outputId": "8569b4a8-5cb8-4d71-8969-4b2fbe1a8400"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-898944afae8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_reshaped_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plt. imgshow throws an error on displaying the image when reshaped\n",
        "Try with cv2 in  colab but not working\n",
        "\n",
        "```\n",
        "import cv2\n",
        "\n",
        "cv2.imshow('img0',img0)\n",
        "cv2.imshow('img0 reshaped',img_reshaped_0)\n",
        "# Maintain output window utill user presses a key\n",
        "cv2.waitKey(0)        \n",
        "\n",
        "# Destroying present windows on screen\n",
        "cv2.destroyAllWindows()\n",
        "```\n",
        "So used the colab patch to display the image.\n",
        "\n",
        "I wanted to see if the one channle reshaping was correct displaying the image.\n",
        "\n"
      ],
      "metadata": {
        "id": "7DHXzT3LnL8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 #not working\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img0)\n",
        "cv2_imshow(img_reshaped_0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "oB5iSPs9nKqs",
        "outputId": "38ee7ecc-54e1-431b-e0eb-a62c2ad1f2c0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6E0780CB90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F6E078C5650>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB7ElEQVR4nO2UP8hxURjAz0VKittd/CuLwSDKICWDDEbdE5OyyMZksTEpg0ky3AwmC2VQdyAKpQwGA5IMhJXrT7crx32H2/flfT/vHzJ93/ebTj3P+XWenvM8APzn70EsFhO/SCQS6XS6Wq1qtdpSqcTzPMuyyWTyNl/ymUiv10ulUofD4XQ6cRz3+Xy30dVqlc1mIYSHw2E4HLbb7dsodtdotVqbzaZSqbwbvV6voVDodDoBADabzXa7nU6n39dLEMRsNkPv6fV6NE2zLMswzPeKu5AkWSgUIpGIYBwMBnK5HABgMpkoinpSCgBQKBQYhlEUhRAKBAI/vyj6Irbf73meF4oNh8Mi0VfJjyGXy1utFkLI4/G8TAoAMBgMDMMsFotisRiNRjHs/p95GAjhbrcTmhaPxzUazWu8ZrO5Xq8L3nw+r9PpXuPFcTwYDF4uF4RQo9F4jVSA4ziEEMdxLpfrbsKns/8nFovF7/fbbDaJRAIAGI/HnU7n+acZjcZcLrder3+P7Pl8pmn6SZ1arY7FYvP5/HYJ9Pt9r9f7jE6lUrnd7tFo9GGnQAifGS2CIMrl8oct1e12SZKUyWQP6+x2e6VSWS6Xt7rj8ZhKpYQV9UPedR9CCCEUzpPJpFarIYQymcxut3v4gf8wb5vwG2+h9UGFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX7u0oC5joy8"
      },
      "source": [
        "## Pre-processing the data\n",
        "\n",
        "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
        "\n",
        "Here you will apply two transformations to the data:\n",
        "- Reshape the data so that it has an extra dimension. The reason for this \n",
        "is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
        "\n",
        "\n",
        "- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n",
        "\n",
        "Remember that these tensors are of type `numpy.ndarray` so you can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "iH6UYkQKjoy8"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1 )\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images / np.max(images)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7lCdn2Vjoy9"
      },
      "source": [
        "Test your function with the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "VR_9q74Gjoy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffcdb9a-b973-4780-b624-5da679d414d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path='/content/drive/MyDrive/ColabNotebooks/TFC/C1/data/mnist3.npz') \n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDBKHnA2joy-"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Maximum pixel value after normalization: 1.0\n",
        "\n",
        "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
        "\n",
        "Shape of one image after reshaping: (28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij8xzIMujoy_"
      },
      "source": [
        "## Defining your callback\n",
        "\n",
        "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached.\n",
        "\n",
        "Define your callback in such a way that it checks for the metric `accuracy` (`acc` can normally be used as well but the grader expects this metric to be called `accuracy` so to avoid getting grading errors define it using the full word)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "MAtFHVRRjoy_"
      },
      "outputs": [],
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      '''\n",
        "      Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "      Args:\n",
        "        epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "        logs (dict) - metric results from the training epoch\n",
        "      '''\n",
        "      print(f\"\\nLOGS : {logs}\\n\")\n",
        "      accuracy= logs.get('accuracy')\n",
        "      if(accuracy is not None and accuracy < 0.995):\n",
        "        pass\n",
        "      else:\n",
        "        #Stop the process\n",
        "        print(f\"\\nAccuracy reached is more then 99,5% : {accuracy}\")     \n",
        "        self.model.stop_training = True\n",
        "\n",
        "### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQeVKh6gjoy_"
      },
      "source": [
        "## Convolutional Model\n",
        "\n",
        "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network.\n",
        "\n",
        "**Your model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**\n",
        "\n",
        "**Hints:**\n",
        "- You can try any architecture for the network but try to keep in mind you don't need a complex one. For instance, only one convolutional layer is needed.\n",
        "- In case you need extra help you can check out an architecture that works pretty well at the end of this notebook.\n",
        "- To avoid timeout issues with the autograder, please limit the number of units in your convolutional and dense layers. An exception will be raised if your model is too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "MvTcWy9BjozA"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "\n",
        "      # Add convolutions and max pooling        \n",
        "        tf.keras.layers.Conv2D(64,(3,3),activation = 'relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPool2D(2,2) ,\n",
        "        tf.keras.layers.Conv2D(64,(3,3),activation = 'relu', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.MaxPool2D(2,2) ,\n",
        "      \n",
        "      # Add input, neurons, outputs \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10,activation = 'softmax')\n",
        "    ]) \n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "convolutional_model().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2nEGKdBxZVj",
        "outputId": "eda95d63-2d32-4839-ba5f-f2c465b42c64"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "Xx9uSOkmjozA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0ce4b3-d991-4434-8801-ede63c42bb34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9628\n",
            "LOGS : {'loss': 0.12059203535318375, 'accuracy': 0.9628000259399414}\n",
            "\n",
            "1875/1875 [==============================] - 109s 58ms/step - loss: 0.1206 - accuracy: 0.9628\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9876\n",
            "LOGS : {'loss': 0.040189117193222046, 'accuracy': 0.987583339214325}\n",
            "\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.0402 - accuracy: 0.9876\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9917\n",
            "LOGS : {'loss': 0.02720441110432148, 'accuracy': 0.9916999936103821}\n",
            "\n",
            "1875/1875 [==============================] - 104s 55ms/step - loss: 0.0272 - accuracy: 0.9917\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9943\n",
            "LOGS : {'loss': 0.01929527148604393, 'accuracy': 0.9943166375160217}\n",
            "\n",
            "1875/1875 [==============================] - 105s 56ms/step - loss: 0.0193 - accuracy: 0.9943\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954\n",
            "LOGS : {'loss': 0.014690039679408073, 'accuracy': 0.9953666925430298}\n",
            "\n",
            "\n",
            "Accuracy reachet is more then 99,5% : 0.9953666925430298\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.0147 - accuracy: 0.9954\n"
          ]
        }
      ],
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Get number of weights\n",
        "model_params = model.count_params()\n",
        "\n",
        "# Unit test to limit the size of the model\n",
        "assert model_params < 1000000, (\n",
        "    f'Your model has {model_params:,} params. For successful grading, please keep it ' \n",
        "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
        ")\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXIO-3BQjozA"
      },
      "source": [
        "If you see the message that you defined in your callback printed out after less than 10 epochs it means your callback worked as expected. You can also double check by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "WEOaOFrajozB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2598cbaf-6af0-48df-8c96-8413bc5f3d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your model was trained for 5 epochs\n"
          ]
        }
      ],
      "source": [
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTmo5HbjjozB"
      },
      "source": [
        "If your callback didn't stop training, one cause might be that you compiled your model using a metric other than `accuracy` (such as `acc`). Make sure you set the metric to `accuracy`. You can check by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCVWXLaDjozB"
      },
      "outputs": [],
      "source": [
        "if not \"accuracy\" in history.model.metrics_names:\n",
        "    print(\"Use 'accuracy' as metric when compiling your model.\")\n",
        "else:\n",
        "    print(\"The metric was correctly defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X36GH_mljozB"
      },
      "source": [
        "## Need more help?\n",
        "\n",
        "Run the following cell to see an architecture that works well for the problem at hand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v3oXuDCjozC"
      },
      "outputs": [],
      "source": [
        "# WE STRONGLY RECOMMEND YOU TO TRY YOUR OWN ARCHITECTURES FIRST\n",
        "# AND ONLY RUN THIS CELL IF YOU WISH TO SEE AN ANSWER\n",
        "\n",
        "import base64\n",
        "\n",
        "encoded_answer = \"CiAgIC0gQSBDb252MkQgbGF5ZXIgd2l0aCAzMiBmaWx0ZXJzLCBhIGtlcm5lbF9zaXplIG9mIDN4MywgUmVMVSBhY3RpdmF0aW9uIGZ1bmN0aW9uIGFuZCBhbiBpbnB1dCBzaGFwZSB0aGF0IG1hdGNoZXMgdGhhdCBvZiBldmVyeSBpbWFnZSBpbiB0aGUgdHJhaW5pbmcgc2V0CiAgIC0gQSBNYXhQb29saW5nMkQgbGF5ZXIgd2l0aCBhIHBvb2xfc2l6ZSBvZiAyeDIKICAgLSBBIEZsYXR0ZW4gbGF5ZXIgd2l0aCBubyBhcmd1bWVudHMKICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTI4IHVuaXRzIGFuZCBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTAgdW5pdHMgYW5kIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbgo=\"\n",
        "encoded_answer = encoded_answer.encode('ascii')\n",
        "answer = base64.b64decode(encoded_answer)\n",
        "answer = answer.decode('ascii')\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23dO1XxnjozC"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a CNN to assist you in the image classification task. Nice job!\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}